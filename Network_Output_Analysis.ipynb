{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ErinMao233/Network-model-output-analysis/blob/main/Network_Output_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What's this for**\n",
        "\n",
        "1.   This is to analyze demand model output, and translate it to user friendly report\n",
        "2.   According to distance, group ICs to 9 groups\n",
        "3.   Compare this time model's period 5 with last time model's period 4 data for # of trips and hauler miles metrics\n",
        "4.   List details of Origin and destination pairs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "crIeDak03ydV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "import google.auth\n",
        "credentials = google.auth.default()\n",
        "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "xGwSjxV-TATL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "554fc312-2fdb-47ed-bdb4-d6f1ed91538d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_df_from_worksheet(spreadsheet, worksheet_name):\n",
        "    worksheet = spreadsheet.worksheet(worksheet_name)\n",
        "    rows = worksheet.get_all_values()\n",
        "    headers = rows.pop(0)\n",
        "    df = pd.DataFrame(rows, columns=headers)\n",
        "    return df"
      ],
      "metadata": {
        "id": "d27dH7obYYrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nijZ14HoUQQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read all data from spreadsheet\n",
        "# read Last PC utilization_details_weekly_adj\n",
        "spreadsheet_key_last_uti='11r1OX29yC5YZ0UPeiqFrGNdpdOMmYEunzF0c1s-hdUs'\n",
        "spreadsheet_last_uti = gc.open_by_key(spreadsheet_key_last_uti)\n",
        "df_last_PC_uti = get_df_from_worksheet(spreadsheet_last_uti, 'utilization_details_weekly')\n",
        "\n",
        "# read Current PC utilization_details_weekly_adj\n",
        "spreadsheet_key_curr_uti='1eZh1Iu3rHxVly2fLCtsUJzAFuimod8ocX6JSLp_ZBM0'\n",
        "spreadsheet_curr_uti = gc.open_by_key(spreadsheet_key_curr_uti)\n",
        "df_curr_PC_uti = get_df_from_worksheet(spreadsheet_curr_uti, 'utilization_details_weekly')\n",
        "\n",
        "# # read IC grouping spreadsheet\n",
        "# spreadsheet_key_grouping='1DuSvbQEtpRHY_hMKx7sSJOOwweEJSZluOL3cqBhrOxg'\n",
        "# spreadsheet_grouping = gc.open_by_key(spreadsheet_key_grouping)\n",
        "# df_IC_grouping = get_df_from_worksheet(spreadsheet_grouping, 'IC Group')\n",
        "\n",
        "# # read Current trip_limits\n",
        "# spreadsheet_key_curr_uti='1_cT6Xp-6_6hKncCDkoafiMCP8CVl2eqOaiD5k2V6RDo'\n",
        "# spreadsheet_curr_uti = gc.open_by_key(spreadsheet_key_curr_uti)\n",
        "# df_curr_trip_limits = get_df_from_worksheet(spreadsheet_curr_uti, 'trip_limits')\n",
        "\n",
        "# # read last trip_limits\n",
        "# spreadsheet_key_last_uti='1szt1hFJKL59eDfvIRXLcB_OWOXoXZpO9UQv-d6KcXrI'\n",
        "# spreadsheet_last_uti = gc.open_by_key(spreadsheet_key_last_uti)\n",
        "# df_last_trip_limits = get_df_from_worksheet(spreadsheet_last_uti, 'trip_limits')"
      ],
      "metadata": {
        "id": "84WinX6mYjFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9cowE1CtvH_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_IC_grouping = pd.DataFrame({\n",
        "    'Group': ['Group1', 'Group1', 'Group1', 'Group1', 'Group1', 'Group1',\n",
        "              'Group2',\n",
        "              'Group3', 'Group3', 'Group3', 'Group3',\n",
        "              'Group4', 'Group4', 'Group4', 'Group4',\n",
        "              'Group5', 'Group5', 'Group5', 'Group5', 'Group5',\n",
        "              'Group6', 'Group6',\n",
        "              'Group7', 'Group7', 'Group7',\n",
        "              'Group8',\n",
        "              'Group9', 'Group9', 'Group9', 'Group9', 'Group9', 'Group9', 'Group9'],\n",
        "    'IC': ['ARVMH', 'BANLH', 'LNVMH', 'ROCIC', 'TOL', 'TOOIC',\n",
        "           'POSMH',\n",
        "           'BM', 'HTNLH', 'OKCIC', 'SAAIC',\n",
        "           'ABUMH', 'BMAIC', 'DEL', 'NNJIC',\n",
        "           'ELYIC', 'HEAIC', 'INDIC', 'TREIC', 'UNIIC',\n",
        "           'CHEIC', 'CONIC',\n",
        "           'BESIC', 'WIND', 'WMEIC',\n",
        "           'HNSIC',\n",
        "           'BIDLH', 'DEN', 'EUGLH', 'KSC', 'MINN', 'MOBLH', 'MOR']\n",
        "})"
      ],
      "metadata": {
        "id": "j69lBORKvsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UNctX1dhyqJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert all 2 tables column to numeric\n",
        "df_last_PC_uti[['period', 'number_of_cars_weekly', 'round_trip_distance', 'hauler_miles']] = \\\n",
        "df_last_PC_uti[['period', 'number_of_cars_weekly', 'round_trip_distance', 'hauler_miles']].apply(pd.to_numeric)\n",
        "df_curr_PC_uti[['period', 'number_of_cars_weekly', 'round_trip_distance', 'hauler_miles']] = \\\n",
        "df_curr_PC_uti[['period', 'number_of_cars_weekly', 'round_trip_distance', 'hauler_miles']].apply(pd.to_numeric)"
      ],
      "metadata": {
        "id": "p6SB_l73Rx0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# design a function to have loop, origins, period, round_trip_distance, hauler_miles, number_of_trips, Group 7 columns\n",
        "def prepare_curr_df(df_uti_name):\n",
        " df_uti = df_uti_name[(df_uti_name['period'] == 5) & (df_uti_name['round_trip_distance'] != 0)]\n",
        " df_uti = df_uti[['loop', 'origins', 'period', 'round_trip_distance', 'hauler_miles', 'number_of_cars_weekly']]\n",
        " df_uti = df_uti.merge(df_IC_grouping, how = 'left', left_on = 'origins', right_on = 'IC')\n",
        " df_uti['number_of_trips'] = np.ceil((df_uti['number_of_cars_weekly']/9).round(1))\n",
        " df_uti.drop(['IC', 'number_of_cars_weekly'], axis = 1, inplace = True)\n",
        " return df_uti\n",
        "\n",
        "def prepare_last_df(df_uti_name):\n",
        " df_uti = df_uti_name[(df_uti_name['period'] == 4) & (df_uti_name['round_trip_distance'] != 0)]\n",
        " df_uti = df_uti[['loop', 'origins', 'period', 'round_trip_distance', 'hauler_miles', 'number_of_cars_weekly']]\n",
        " df_uti = df_uti.merge(df_IC_grouping, how = 'left', left_on = 'origins', right_on = 'IC')\n",
        " df_uti['number_of_trips'] = np.ceil((df_uti['number_of_cars_weekly']/9).round(1))\n",
        " df_uti.drop(['IC', 'number_of_cars_weekly'], axis = 1, inplace = True)\n",
        " return df_uti\n",
        "\n",
        "# get clean data for 2 raw tables\n",
        "df_curr_PC_uti = prepare_curr_df(df_curr_PC_uti)\n",
        "df_last_PC_uti = prepare_last_df(df_last_PC_uti)\n",
        "# df_curr_PC_uti"
      ],
      "metadata": {
        "id": "La7t9-rG5j5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make destination column\n",
        "df_last_PC_uti['destination'] = df_last_PC_uti['loop'].str.split(',').apply(lambda x: x[1])\n",
        "df_curr_PC_uti['destination'] = df_curr_PC_uti['loop'].str.split(',').apply(lambda x: x[1])"
      ],
      "metadata": {
        "id": "cXkH8NuiSKdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Is_destination_An_Origin column\n",
        "def Create_IsOrigin_col(df_uti_name):\n",
        "  df_uti = df_uti_name\n",
        "  found = False\n",
        "  Is_destination_An_Origin = []\n",
        "  for j in range(0, len(df_uti)):\n",
        "    for i in range(0, len(df_IC_grouping)):\n",
        "        if df_uti['destination'].iloc[j] == df_IC_grouping['IC'].iloc[i]:\n",
        "          found = True\n",
        "          Is_destination_An_Origin.append(True)\n",
        "          break\n",
        "    else:\n",
        "      Is_destination_An_Origin.append(False)\n",
        "  df_uti['Is_destination_An_Origin'] = pd.Series(Is_destination_An_Origin)\n",
        "\n",
        "\n",
        "\n",
        "Create_IsOrigin_col(df_last_PC_uti)\n",
        "Create_IsOrigin_col(df_curr_PC_uti)\n",
        "# df_curr_PC_uti"
      ],
      "metadata": {
        "id": "02QThcopeyv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zsjJ-rt1GSpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Create_ODPair(df_uti_name):\n",
        "  df_uti = df_uti_name\n",
        "  OD_pair = []\n",
        "  for i in range(0, len(df_uti)):\n",
        "    if df_uti['Is_destination_An_Origin'].iloc[i] == False:\n",
        "      OD_pair.append(df_uti['origins'].iloc[i] + ',' + df_uti['destination'].iloc[i])\n",
        "    elif df_uti['origins'].iloc[i] <= df_uti['destination'].iloc[i]:\n",
        "      OD_pair.append(df_uti['origins'].iloc[i] + ',' + df_uti['destination'].iloc[i])\n",
        "    else:\n",
        "      OD_pair.append(df_uti['destination'].iloc[i] + ',' + df_uti['origins'].iloc[i])\n",
        "  df_uti['OD_pair'] = pd.Series(OD_pair)\n",
        "Create_ODPair(df_last_PC_uti)\n",
        "Create_ODPair(df_curr_PC_uti)"
      ],
      "metadata": {
        "id": "vdkI-Jzy3zHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LscI-dH0SqFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bYaxmbyaGRoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_PC_comp = df_curr_PC_uti.merge(df_last_PC_uti, left_on = ['origins', 'period', 'OD_pair', 'round_trip_distance', 'Group', 'loop']\\\n",
        "                    , right_on = ['origins', 'period', 'OD_pair', 'round_trip_distance', 'Group', 'loop'], how = 'outer')\n",
        "# df_PC_comp = df_curr_PC_uti.merge(df_last_PC_uti, left_on = ['OD_pair']\\\n",
        "#                     , right_on = ['OD_pair'], how = 'left')\n",
        "df_PC_comp.rename(columns = {\"number_of_trips_x\": \"number_of_trips_curr_PC\", \"number_of_trips_y\": \"number_of_trips_last_PC\",\\\n",
        "                             \"hauler_miles_x\": \"hauler_miles_curr_PC\", \"hauler_miles_y\": \"hauler_miles_last_PC\",\\\n",
        "                             \"destination_x\": \"destination_curr_PC\", \"destination_y\": \"destination_last_PC\"}, inplace = True)\n",
        "df_PC_comp.drop(columns = ['Is_destination_An_Origin_x', 'Is_destination_An_Origin_y'], inplace = True)\n",
        "df_PC_comp['number_of_trips_curr_PC'].fillna(0, inplace = True)\n",
        "df_PC_comp['number_of_trips_last_PC'].fillna(0, inplace = True)\n",
        "df_PC_comp['hauler_miles_curr_PC'].fillna(0, inplace = True)\n",
        "df_PC_comp['hauler_miles_last_PC'].fillna(0, inplace = True)\n"
      ],
      "metadata": {
        "id": "WlF7t-4o5j-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5ZqR1zsKxV-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/My Drive/output.csv'\n",
        "with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
        "  df_PC_comp.to_csv(f)"
      ],
      "metadata": {
        "id": "0Wac6_K6XR_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wacENMJLxWB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FDecAWN7xWEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # get last PC origin level trips df\n",
        "# df_last_PC_uti_4 = df_last_PC_uti[(df_last_PC_uti['period'] == 4) & (df_last_PC_uti['round_trip_distance'] != 0)]\n",
        "# df_last_PC_uti_4 = df_last_PC_uti_4.groupby('origins').sum()['number_of_cars_weekly']/9\n",
        "\n",
        "# df_curr_PC_uti_4 = df_curr_PC_uti[(df_curr_PC_uti['period'] == 4) & (df_curr_PC_uti['round_trip_distance'] != 0)]\n",
        "# df_curr_PC_uti_4 = df_curr_PC_uti_4.groupby('origins').sum()['number_of_cars_weekly']/9\n",
        "\n",
        "# df_PC_comp = df_curr_PC_uti_4.to_frame().merge(df_last_PC_uti_4, on = 'origins', how = 'left')\n",
        "# df_PC_comp.rename(columns = {\"number_of_cars_weekly_x\": \"Num_trips_curr_PC\", \"number_of_cars_weekly_y\": \"Num_trips_last_PC\"}, inplace = 'True')\n",
        "# df_PC_comp['Diff'] = df_PC_comp['Num_trips_curr_PC'] - df_PC_comp['Num_trips_last_PC']\n",
        "# df_PC_comp['Diff %'] = (df_PC_comp['Num_trips_curr_PC'] - df_PC_comp['Num_trips_last_PC']) / df_PC_comp['Num_trips_last_PC']\n",
        "\n"
      ],
      "metadata": {
        "id": "Yp7prfmNqSbJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}